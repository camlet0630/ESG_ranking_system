{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camlet0630/ESG_ranking_system/blob/main/nn_v0_pure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "VlorVVvt4ewJ"
      },
      "id": "VlorVVvt4ewJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "listed-lafayette",
      "metadata": {
        "id": "listed-lafayette"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import random\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "device = torch.device('cuda', 0) if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 載入 embedding_tensor.pt & label_data.csv\n",
        "embedding_tensor = torch.load(\"/content/embedding_tensor.pt\")\n",
        "print(embedding_tensor.shape)\n",
        "label_data = pd.read_csv(\"/content/label_data.csv\")\n",
        "\n",
        "# config\n",
        "config = {\"seed\": 168,\n",
        "          \"learning_rate\": 3e-4,\n",
        "          \"batch_size\": 64, #128 256訓練不了\n",
        "          \"epochs\": 300}\n",
        "\n",
        "def set_random_seed(seed, deterministic=False):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "set_random_seed(config[\"seed\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is_WhE33eEAq",
        "outputId": "d5389c00-551c-4adc-a91b-a470acaafe94"
      },
      "id": "is_WhE33eEAq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1805, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "personal-working",
      "metadata": {
        "id": "personal-working"
      },
      "source": [
        "# Func\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation Metrics"
      ],
      "metadata": {
        "id": "mYZVnN8tsJc7"
      },
      "id": "mYZVnN8tsJc7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "short-electricity",
      "metadata": {
        "id": "short-electricity"
      },
      "outputs": [],
      "source": [
        "# 函數: 計算 Accuracy\n",
        "def ACCscore_m_label(y_true, pred):\n",
        "    accuracy_l = [ans.all() for ans in (pred == y_true)]\n",
        "    accuracy = np.array(accuracy_l).mean()\n",
        "    return accuracy\n",
        "\n",
        "# 函數: 計算 Precision, Recall\n",
        "def PRscore_m_label(y_true, pred):\n",
        "    hit_matrix = np.zeros_like(pred)\n",
        "    hit_matrix[np.where((pred == y_true) & (y_true > 0))] = 1\n",
        "    tp = hit_matrix.sum(axis=1)\n",
        "    pred_sum = pred.sum(axis=1)\n",
        "    true_sum = y_true.sum(axis=1)\n",
        "    precision_l = []\n",
        "    recall_l = []\n",
        "    for ix in range(tp.shape[0]):\n",
        "        precision_score = (1.0 if true_sum[ix] == 0 else 0.0) if pred_sum[ix] == 0 else tp[ix]/pred_sum[ix]\n",
        "        recall_score = (1.0 if pred_sum[ix] == 0 else 0.0) if true_sum[ix] == 0 else tp[ix]/true_sum[ix]\n",
        "        precision_l.append(precision_score)\n",
        "        recall_l.append(recall_score)\n",
        "    precision = np.array(precision_l).mean()\n",
        "    recall = np.array(recall_l).mean()\n",
        "    return precision, recall\n",
        "\n",
        "# 函數: 計算 F1-score\n",
        "def f1(precision, recall):\n",
        "    f1_score = 0\n",
        "    if (precision + recall) !=0:\n",
        "        f1_score = (2 * precision * recall) / (precision + recall)\n",
        "    return f1_score\n",
        "\n",
        "# 函數: 一次同時計算所有評估指標\n",
        "def score(y_true, pred):\n",
        "    accuracy = ACCscore_m_label(y_true, pred)\n",
        "    precision, recall = PRscore_m_label(y_true, pred)\n",
        "    f1_score = f1(precision, recall)\n",
        "    return accuracy, precision, recall, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unable-lotus",
      "metadata": {
        "id": "unable-lotus"
      },
      "source": [
        "#### Calculate Class Weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "earlier-baghdad",
      "metadata": {
        "id": "earlier-baghdad"
      },
      "outputs": [],
      "source": [
        "# Function: Class weight calculation\n",
        "def get_class_weight(df, labels):\n",
        "    # 計算每個類別的「正樣本數量」，儲存成 class_pos_count 列表\n",
        "    class_pos_count = np.zeros(len(labels))\n",
        "    # 計算每個類別的「負樣本數量」，儲存成 class_neg_count 列表\n",
        "    class_neg_count = np.zeros(len(labels))\n",
        "    # 遞迴\n",
        "    for i in range(len(labels)):\n",
        "        label = labels[i]\n",
        "        positive, negative = df[label].value_counts()[1.0], df[label].value_counts()[0.0]\n",
        "        class_pos_count[i], class_neg_count[i] = positive, negative\n",
        "    # 計算「正樣本權重」\n",
        "    class_pos_weight = np.ones_like(class_pos_count)\n",
        "    for cdx, (pos_count, neg_count) in enumerate(zip(class_pos_count, class_neg_count)):\n",
        "        total_count = pos_count + neg_count\n",
        "        postive_weights = total_count/(2*pos_count)\n",
        "        negtive_weights = total_count/(2*neg_count)\n",
        "        class_pos_weight[cdx] = (postive_weights/negtive_weights)\n",
        "    return torch.as_tensor(class_pos_weight, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sublime-healthcare",
      "metadata": {
        "id": "sublime-healthcare"
      },
      "source": [
        "#### Print out Class Weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "noble-collins",
      "metadata": {
        "id": "noble-collins"
      },
      "outputs": [],
      "source": [
        "def print_class_weight(task_label):\n",
        "    print(\"<<各類別資料數>>\")\n",
        "    print(task_label.sum())\n",
        "    label_list = task_label.columns\n",
        "    class_weight = get_class_weight(task_label, label_list)\n",
        "    print()\n",
        "    print(\"<<目標變數與權重對應>>\")\n",
        "    print(f\"目標變數共有 {len(label_list)} 類\")\n",
        "    for c, w in zip(label_list, class_weight):\n",
        "        print(f\"{c}: {round(float(w), 2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "concerned-expert",
      "metadata": {
        "id": "concerned-expert"
      },
      "source": [
        "#### Build Class: Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tough-congress",
      "metadata": {
        "id": "tough-congress"
      },
      "outputs": [],
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, embeddings, label_list):\n",
        "        self.embeddings = embeddings\n",
        "        self.labels = label_list.to_numpy()\n",
        "\n",
        "    def __getLabels__(self):\n",
        "        return (self.labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.embeddings[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stretch-balloon",
      "metadata": {
        "id": "stretch-balloon"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "racial-flesh",
      "metadata": {
        "id": "racial-flesh"
      },
      "source": [
        "#### Model Architecture\n",
        "- 實現一個神經網絡模型。該模型包含了兩層隱藏層架構並使用 dropout 機制"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nn.Module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv0_ibPanX7P",
        "outputId": "2685cf37-eb0a-47e9-d9ca-26e1c4a52be6"
      },
      "id": "tv0_ibPanX7P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.modules.module.Module'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sapphire-warehouse",
      "metadata": {
        "id": "sapphire-warehouse"
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Module): # multitask + teacherForcing() + posiNega\n",
        "    def __init__(self, output_size_1=3, output_size_2=22, output_size_3=3, dropout_rate=0.5):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear_1 = nn.Linear(768, 256) # Stage_0\n",
        "        self.linear_2 = nn.Linear(256, 64) # Stage_0\n",
        "        self.linear_3 = nn.Linear(64, output_size_1) # Stage_1_rough_NN (得到 rough_output)\n",
        "        self.linear_4 = nn.Linear(64, 32)  # Stage_1_noCat_NN（得到 noCat_output）\n",
        "        self.linear_5 = nn.Linear(32+output_size_1, output_size_2) # Stage_2_NN（得到 precise_output）\n",
        "        self.output_layers = nn.ModuleList([nn.Sequential(nn.Linear(32+output_size_1, output_size_3), nn.Softmax) for _ in range(output_size_2)]) # 22 個 Stage_2.0_NN\n",
        "\n",
        "    def forward(self, embeddings, y_rough_true, alpha):\n",
        "        shared_output = self.linear_1(embeddings)\n",
        "        shared_output = self.relu(shared_output)\n",
        "        shared_output = self.linear_2(shared_output)\n",
        "        shared_output = self.relu(shared_output)\n",
        "        shared_output = self.dropout(shared_output)\n",
        "        # 已經走完 Stage_0 得到 shared_output(64)\n",
        "        rough_output = self.linear_3(shared_output)\n",
        "        noCat_output = self.linear_4(shared_output)\n",
        "        rept_rough_output = alpha * y_rough_true + (1-alpha) * rough_output # 當 epoch > 10 開始 alpha 1->0\n",
        "        withCat_output = torch.cat((rept_rough_output, noCat_output), axis=1)\n",
        "        withCat_output = self.relu(withCat_output)\n",
        "        withCat_output = self.dropout(withCat_output)\n",
        "        # 已經 concat 完得到 withCat_output\n",
        "        # precise_output = self.linear_5(withCat_output)\n",
        "        precise_output = [output_layer(withCat_output) for output_layer in self.output_layers] # 22x3\n",
        "        return rough_output, precise_output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "activated-spanking",
      "metadata": {
        "id": "activated-spanking"
      },
      "source": [
        "#### Function for model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "strange-reply",
      "metadata": {
        "id": "strange-reply"
      },
      "outputs": [],
      "source": [
        "def train(model, class_weight, train_set, val_set, patience=100):\n",
        "    train_loader = DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "    # Loss Function\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=class_weight)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"learning_rate\"])\n",
        "\n",
        "    # Putting the model on the GPU to run\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    val_best_f1 = float(-np.inf)\n",
        "    iteration_num = 0\n",
        "    epoch_num = 0\n",
        "\n",
        "    epochs = config[\"epochs\"]\n",
        "\n",
        "    while True:\n",
        "        if iteration_num >= patience:\n",
        "            break\n",
        "\n",
        "        # Train and save training results\n",
        "        loss_list = []\n",
        "        accuracy_list = []\n",
        "        precision_list = []\n",
        "        recall_list = []\n",
        "        f1_list = []\n",
        "\n",
        "        # Set the model to the \"training\" state (Layers such as Dropout will be triggered only)\n",
        "        model.train()\n",
        "\n",
        "        for train_embeddings, train_labels in tqdm(train_loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            train_embeddings = train_embeddings.to(device)\n",
        "            train_labels = train_labels.to(device)\n",
        "\n",
        "            output = model(train_embeddings)\n",
        "\n",
        "            batch_loss = criterion(output, train_labels.float())\n",
        "\n",
        "            # Back propagation\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            output = output.cpu().detach()\n",
        "            pred = (output > 0).cpu()\n",
        "            y_true = (train_labels > 0).cpu()\n",
        "\n",
        "            # Calculate the performance of each batch and save it\n",
        "            loss = batch_loss.item()\n",
        "            accuracy, precision, recall, f1_score= score(y_true, pred)\n",
        "\n",
        "            loss_list.append(loss)\n",
        "            accuracy_list.append(accuracy)\n",
        "            precision_list.append(precision)\n",
        "            recall_list.append(recall)\n",
        "            f1_list.append(f1_score)\n",
        "\n",
        "        # Calculate the performance of each epoch and save it\n",
        "        train_loss = np.array(loss_list).mean()\n",
        "        train_accuracy = np.array(accuracy_list).mean()\n",
        "        train_precision = np.array(precision_list).mean()\n",
        "        train_recall = np.array(recall_list).mean()\n",
        "        train_f1 = np.array(f1_list).mean()\n",
        "\n",
        "\n",
        "        # Evaluate the current model performance using validate dataset\n",
        "        loss_list = []\n",
        "        accuracy_list = []\n",
        "        precision_list = []\n",
        "        recall_list = []\n",
        "        pred_list = []\n",
        "        f1_list = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for val_embeddings, val_labels in tqdm(val_loader):\n",
        "\n",
        "                val_embeddings = val_embeddings.to(device)\n",
        "                val_labels = val_labels.to(device)\n",
        "\n",
        "                output = model(val_embeddings)\n",
        "\n",
        "                batch_loss = criterion(output, val_labels.float())\n",
        "\n",
        "                output = output.cpu()\n",
        "                pred = (output > 0).cpu()\n",
        "                sum_pred = torch.sum(pred, dim=1)\n",
        "                non_label_case_idx = (sum_pred < 1).nonzero()\n",
        "\n",
        "                if non_label_case_idx.shape[0] != 0:\n",
        "                    non_label_case = output[non_label_case_idx]\n",
        "                    max_col = torch.argmax(non_label_case, dim=-1)\n",
        "                    raw = non_label_case_idx.reshape(-1,1)\n",
        "                    pred_np = pred.numpy()\n",
        "                    for idx in range(raw.shape[0]):\n",
        "                        pred_np[raw[idx]][max_col[idx]] = True\n",
        "                    pred = torch.from_numpy(pred_np)\n",
        "                pred_list.extend(pred.numpy().astype('float32'))\n",
        "                y_true = (val_labels > 0).cpu()\n",
        "\n",
        "                # Calculate the performance of each batch and save it\n",
        "                loss = batch_loss.item()\n",
        "                accuracy, precision, recall, f1_score = score(y_true, pred)\n",
        "\n",
        "                loss_list.append(loss)\n",
        "                accuracy_list.append(accuracy)\n",
        "                precision_list.append(precision)\n",
        "                recall_list.append(recall)\n",
        "                f1_list.append(f1_score)\n",
        "\n",
        "            # Calculate the performance of each epoch and save it\n",
        "            val_loss = np.array(loss_list).mean()\n",
        "            val_accuracy = np.array(accuracy_list).mean()\n",
        "            val_precision = np.array(precision_list).mean()\n",
        "            val_recall = np.array(recall_list).mean()\n",
        "            val_f1 = np.array(f1_list).mean()\n",
        "\n",
        "\n",
        "        if val_f1 > val_best_f1:\n",
        "            ## val result\n",
        "            val_best_f1 = val_f1\n",
        "            val_best_loss = val_loss\n",
        "            val_best_accuracy = val_accuracy\n",
        "            val_best_precision = val_precision\n",
        "            val_best_recall = val_recall\n",
        "            ## train result\n",
        "            train_best_f1 = train_f1\n",
        "            train_best_loss = train_loss\n",
        "            train_best_accuracy = train_accuracy\n",
        "            train_best_precision = train_precision\n",
        "            train_best_recall = train_recall\n",
        "            ## other result\n",
        "            best_model = model\n",
        "            iteration_num = 0\n",
        "            best_pred_list = pred_list\n",
        "        else:\n",
        "            iteration_num += 1\n",
        "\n",
        "        epoch_num += 1\n",
        "        # Print out the results of each Epoch\n",
        "        print(f'Epochs: {epoch_num + 1} || Train Loss: {train_loss: .3f}, Accuracy: {train_accuracy: .3f}, Precision: {train_precision: .3f}, Recall:{train_recall: .3f}, F1: {train_f1: .3f} || Val Loss: {val_loss: .3f}, Accuracy: {val_accuracy: .3f}, Precision: {val_precision: .3f}, Recall:{val_recall: .3f}, Val F1: {val_f1: .3f} || Best F1: {val_best_f1: .3f}, Iter: {iteration_num: .0f}')\n",
        "\n",
        "    train_result = [train_best_loss, train_best_accuracy, train_best_precision,\n",
        "                    train_best_recall, train_best_f1]\n",
        "    val_result = [val_best_loss, val_best_accuracy, val_best_precision,\n",
        "                  val_best_recall, val_best_f1]\n",
        "\n",
        "    return model, train_result, val_result, best_pred_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ldMTNCKrfGlt"
      },
      "id": "ldMTNCKrfGlt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "prospective-sleeve",
      "metadata": {
        "id": "prospective-sleeve"
      },
      "source": [
        "#### 10-Fold Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "surprised-worse",
      "metadata": {
        "id": "surprised-worse"
      },
      "outputs": [],
      "source": [
        "def kfold_train_m_label(embedding_tensor, task_label, output_size, nfold=10):\n",
        "\n",
        "    # 10 fold\n",
        "    skf = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=config[\"seed\"])\n",
        "    kfold_result = pd.DataFrame(columns=['Fold', 'train_loss', 'train_accuracy', 'train_precision',\n",
        "                                    'train_recall', 'train_f1', 'val_loss', 'val_accuracy',\n",
        "                                    'val_precision', 'val_recall', 'val_f1'])\n",
        "\n",
        "    counts_true = pd.DataFrame(columns = [\"num_label\"])\n",
        "    counts_pred = pd.DataFrame(columns = [\"num_label\"])\n",
        "\n",
        "    pred_col_name = [\"idx\"]\n",
        "    for o_idx in range(output_size):\n",
        "        pred_col_name.append(f\"{o_idx}\")\n",
        "    pred_result = pd.DataFrame(columns=pred_col_name)\n",
        "\n",
        "    for fold_i, (train_fold, test_fold) in enumerate(skf.split(embedding_tensor, task_label.to_numpy().argmax(1))):\n",
        "\n",
        "        print(f\"Fold: {fold_i} | Train shape: {len(train_fold)} | Val shape: {len(test_fold)}\")\n",
        "\n",
        "        ## Preparation of training and validation datasets\n",
        "        embedding_train, embedding_val = embedding_tensor[train_fold], embedding_tensor[test_fold]\n",
        "        label_train, label_val = task_label.iloc[train_fold,:], task_label.iloc[test_fold,:]\n",
        "\n",
        "        class_weight = print_class_weight(label_train)\n",
        "\n",
        "        ## Actual number of labels\n",
        "        actual_label_count = pd.DataFrame(sorted(Counter(label_val.sum(axis=1)).items()),\n",
        "                                        columns = [\"num_label\", f\"true_{fold_i}\"])\n",
        "        counts_true = pd.merge(counts_true, actual_label_count, how=\"outer\", on = \"num_label\")\n",
        "\n",
        "        ## Convert to Dataset data type\n",
        "        train_set = Dataset(embedding_train, label_train)\n",
        "        val_set = Dataset(embedding_val, label_val)\n",
        "\n",
        "        print(f\"Train 各類別資料量:\", np.sum(train_set.__getLabels__(), axis=0))\n",
        "        print(f\"Val 各類別資料量:\", np.sum(val_set.__getLabels__(), axis=0))\n",
        "        model = Classifier(output_size=output_size)\n",
        "\n",
        "        ## Model Training\n",
        "        model, train_result, val_result, pred_list = train(model, class_weight, train_set, val_set)\n",
        "\n",
        "        ## Record model evaluation results\n",
        "        kfold_result = kfold_result.append([{\"Fold\": fold_i,\n",
        "                                        \"train_loss\":train_result[0],\n",
        "                                        \"train_accuracy\":train_result[1],\n",
        "                                        \"train_precision\":train_result[2],\n",
        "                                        \"train_recall\":train_result[3],\n",
        "                                        \"train_f1\":train_result[4],\n",
        "                                        \"val_loss\": val_result[0],\n",
        "                                        \"val_accuracy\": val_result[1],\n",
        "                                        \"val_precision\": val_result[2],\n",
        "                                        \"val_recall\": val_result[3],\n",
        "                                        \"val_f1\": val_result[4]}])\n",
        "\n",
        "\n",
        "        ## Prediction results\n",
        "        pred_list = np.array(pred_list)\n",
        "\n",
        "        new_record = {}\n",
        "        new_record['idx'] = test_fold\n",
        "\n",
        "        for o_idx in range(1, len(pred_col_name)):\n",
        "            new_record[pred_col_name[o_idx]] = pred_list[:,o_idx-1]\n",
        "\n",
        "        pred_result = pred_result.append(pd.DataFrame(new_record), ignore_index=True)\n",
        "        print(\"-\"*100)\n",
        "\n",
        "        ## Predicted number of labels\n",
        "        pred_label_count = pd.DataFrame(sorted(Counter(pred_list.sum(axis=1)).items()),\n",
        "                          columns=[\"num_label\", f\"pred_{fold_i}\"])\n",
        "        counts_pred = pd.merge(counts_pred, pred_label_count, how=\"outer\", on = \"num_label\")\n",
        "\n",
        "\n",
        "    return kfold_result, pred_result, counts_true, counts_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "boring-captain",
      "metadata": {
        "id": "boring-captain"
      },
      "source": [
        "# Mainfunction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "passive-ghost",
      "metadata": {
        "id": "passive-ghost"
      },
      "outputs": [],
      "source": [
        "kfold_result_DL, pred_result_DL, counts_true_DL, counts_pred_DL = kfold_train_m_label(embedding_tensor,\n",
        "                                                                                      label_data,\n",
        "                                                                                      label_data.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "consecutive-stand",
      "metadata": {
        "id": "consecutive-stand"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "micro-attack",
      "metadata": {
        "id": "micro-attack",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "fe454951-0fe3-4d05-818f-f46ba0b14823"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-198172b1a64f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_result_DL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_result_DL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"idx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred_result_DL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfold_result_DL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfold_result_DL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pred_result_DL' is not defined"
          ]
        }
      ],
      "source": [
        "pred_result_DL = pred_result_DL.sort_values(\"idx\")\n",
        "pred_result_DL.reset_index(inplace=True, drop=True)\n",
        "display(kfold_result_DL)\n",
        "display(kfold_result_DL.mean()[2:])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Metrics_ new ver.\n",
        "Multilabel Classification 是要對每一個 class 算分數\n",
        "\n",
        "\n",
        "可參考: https://towardsdatascience.com/evaluating-multi-label-classifiers-a31be83da6ea"
      ],
      "metadata": {
        "id": "YAtdcoosgm6d"
      },
      "id": "YAtdcoosgm6d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJqhgniQgm6d"
      },
      "outputs": [],
      "source": [
        "# 函數: 計算 Accuracy\n",
        "def ACCscore_m_label(y_true, pred):\n",
        "    accuracy_l = (pred == y_true)\n",
        "    accuracy = np.array(accuracy_l).mean()\n",
        "    return accuracy\n",
        "\n",
        "# 函數: 計算 Precision, Recall\n",
        "def PRscore_m_label(y_true, pred):\n",
        "    hit_matrix = np.zeros_like(pred)\n",
        "    hit_matrix[np.where((pred == y_true) & (y_true > 0))] = 1\n",
        "    tp = hit_matrix.sum(axis=1)\n",
        "    pred_sum = pred.sum(axis=1)\n",
        "    true_sum = y_true.sum(axis=1)\n",
        "    precision_l = []\n",
        "    recall_l = []\n",
        "    for ix in range(tp.shape[0]):\n",
        "        precision_score = (1.0 if true_sum[ix] == 0 else 0.0) if pred_sum[ix] == 0 else tp[ix]/pred_sum[ix]\n",
        "        recall_score = (1.0 if pred_sum[ix] == 0 else 0.0) if true_sum[ix] == 0 else tp[ix]/true_sum[ix]\n",
        "        precision_l.append(precision_score)\n",
        "        recall_l.append(recall_score)\n",
        "    precision = np.array(precision_l).mean()\n",
        "    recall = np.array(recall_l).mean()\n",
        "    return precision, recall\n",
        "\n",
        "# 函數: 計算 F1-score\n",
        "def f1(precision, recall):\n",
        "    f1_score = 0\n",
        "    if (precision + recall) !=0:\n",
        "        f1_score = (2 * precision * recall) / (precision + recall)\n",
        "    return f1_score\n",
        "\n",
        "# 函數: 一次同時計算所有評估指標\n",
        "def score(y_true, pred):\n",
        "    accuracy = ACCscore_m_label(y_true, pred)\n",
        "    precision, recall = PRscore_m_label(y_true, pred)\n",
        "    f1_score = f1(precision, recall)\n",
        "    return accuracy, precision, recall, f1_score"
      ],
      "id": "aJqhgniQgm6d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o76Rbrg0p4Kt"
      },
      "source": [
        "# Function for model training"
      ],
      "id": "o76Rbrg0p4Kt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbjdm9U9u-ne"
      },
      "outputs": [],
      "source": [
        "def train(model, class_weight, train_set, val_set, patience=100):\n",
        "    train_loader = DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "    # Loss Function\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=class_weight)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"learning_rate\"])\n",
        "\n",
        "    # Putting the model on the GPU to run\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    val_best_f1 = float(-np.inf)\n",
        "    iteration_num = 0\n",
        "    epoch_num = 0\n",
        "\n",
        "    epochs = config[\"epochs\"]\n",
        "\n",
        "    while True:\n",
        "        if iteration_num >= patience:\n",
        "            break\n",
        "\n",
        "        # Train and save training results\n",
        "        loss_list = []\n",
        "        accuracy_list = []\n",
        "        precision_list = []\n",
        "        recall_list = []\n",
        "        f1_list = []\n",
        "\n",
        "        # Set the model to the \"training\" state (Layers such as Dropout will be triggered only)\n",
        "        model.train()\n",
        "\n",
        "        for train_embeddings, train_labels in tqdm(train_loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            train_embeddings = train_embeddings.to(device)\n",
        "            train_labels = train_labels.to(device)\n",
        "\n",
        "            output = model(train_embeddings)\n",
        "\n",
        "            batch_loss = criterion(output, train_labels.float())\n",
        "\n",
        "            # Back propagation\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            output = output.cpu().detach()\n",
        "            pred = (output > 0).cpu()\n",
        "            y_true = (train_labels > 0).cpu()\n",
        "\n",
        "            # Calculate the performance of each batch and save it\n",
        "            loss = batch_loss.item()\n",
        "            accuracy, precision, recall, f1_score= score(y_true, pred)\n",
        "\n",
        "            loss_list.append(loss)\n",
        "            accuracy_list.append(accuracy)\n",
        "            precision_list.append(precision)\n",
        "            recall_list.append(recall)\n",
        "            f1_list.append(f1_score)\n",
        "\n",
        "        # Calculate the performance of each epoch and save it\n",
        "        train_loss = np.array(loss_list).mean()\n",
        "        train_accuracy = np.array(accuracy_list).mean()\n",
        "        train_precision = np.array(precision_list).mean()\n",
        "        train_recall = np.array(recall_list).mean()\n",
        "        train_f1 = np.array(f1_list).mean()\n",
        "\n",
        "\n",
        "        # Evaluate the current model performance using validate dataset\n",
        "        loss_list = []\n",
        "        accuracy_list = []\n",
        "        precision_list = []\n",
        "        recall_list = []\n",
        "        pred_list = []\n",
        "        f1_list = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for val_embeddings, val_labels in tqdm(val_loader):\n",
        "\n",
        "                val_embeddings = val_embeddings.to(device)\n",
        "                val_labels = val_labels.to(device)\n",
        "\n",
        "                output = model(val_embeddings)\n",
        "\n",
        "                batch_loss = criterion(output, val_labels.float())\n",
        "\n",
        "                output = output.cpu()\n",
        "                pred = (output > 0).cpu()\n",
        "                sum_pred = torch.sum(pred, dim=1)\n",
        "                non_label_case_idx = (sum_pred < 1).nonzero()\n",
        "\n",
        "                if non_label_case_idx.shape[0] != 0:\n",
        "                    non_label_case = output[non_label_case_idx]\n",
        "                    max_col = torch.argmax(non_label_case, dim=-1)\n",
        "                    raw = non_label_case_idx.reshape(-1,1)\n",
        "                    pred_np = pred.numpy()\n",
        "                    for idx in range(raw.shape[0]):\n",
        "                        pred_np[raw[idx]][max_col[idx]] = True\n",
        "                    pred = torch.from_numpy(pred_np)\n",
        "                pred_list.extend(pred.numpy().astype('float32'))\n",
        "                y_true = (val_labels > 0).cpu()\n",
        "\n",
        "                # Calculate the performance of each batch and save it\n",
        "                loss = batch_loss.item()\n",
        "                accuracy, precision, recall, f1_score = score(y_true, pred)\n",
        "\n",
        "                loss_list.append(loss)\n",
        "                accuracy_list.append(accuracy)\n",
        "                precision_list.append(precision)\n",
        "                recall_list.append(recall)\n",
        "                f1_list.append(f1_score)\n",
        "\n",
        "            # Calculate the performance of each epoch and save it\n",
        "            val_loss = np.array(loss_list).mean()\n",
        "            val_accuracy = np.array(accuracy_list).mean()\n",
        "            val_precision = np.array(precision_list).mean()\n",
        "            val_recall = np.array(recall_list).mean()\n",
        "            val_f1 = np.array(f1_list).mean()\n",
        "\n",
        "\n",
        "        if val_f1 > val_best_f1:\n",
        "            ## val result\n",
        "            val_best_f1 = val_f1\n",
        "            val_best_loss = val_loss\n",
        "            val_best_accuracy = val_accuracy\n",
        "            val_best_precision = val_precision\n",
        "            val_best_recall = val_recall\n",
        "            ## train result\n",
        "            train_best_f1 = train_f1\n",
        "            train_best_loss = train_loss\n",
        "            train_best_accuracy = train_accuracy\n",
        "            train_best_precision = train_precision\n",
        "            train_best_recall = train_recall\n",
        "            ## other result\n",
        "            best_model = model\n",
        "            iteration_num = 0\n",
        "            best_pred_list = pred_list\n",
        "        else:\n",
        "            iteration_num += 1\n",
        "\n",
        "        epoch_num += 1\n",
        "        # Print out the results of each Epoch\n",
        "        print(f'Epochs: {epoch_num + 1} || Train Loss: {train_loss: .3f}, Accuracy: {train_accuracy: .3f}, Precision: {train_precision: .3f}, Recall:{train_recall: .3f}, F1: {train_f1: .3f} || Val Loss: {val_loss: .3f}, Accuracy: {val_accuracy: .3f}, Precision: {val_precision: .3f}, Recall:{val_recall: .3f}, Val F1: {val_f1: .3f} || Best F1: {val_best_f1: .3f}, Iter: {iteration_num: .0f}')\n",
        "\n",
        "    train_result = [train_best_loss, train_best_accuracy, train_best_precision,\n",
        "                    train_best_recall, train_best_f1]\n",
        "    val_result = [val_best_loss, val_best_accuracy, val_best_precision,\n",
        "                  val_best_recall, val_best_f1]\n",
        "\n",
        "    return model, train_result, val_result, best_pred_list"
      ],
      "id": "lbjdm9U9u-ne"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wyQ9wHisu6Fu"
      },
      "id": "wyQ9wHisu6Fu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1DJtqZlp4Ku"
      },
      "outputs": [],
      "source": [
        "def train(model, class_weight, train_set, val_set, patience=100):\n",
        "    train_loader = DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "    # Loss Function\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=class_weight)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"learning_rate\"])\n",
        "\n",
        "    # Putting the model on the GPU to run\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    val_best_f1 = float(-np.inf)\n",
        "    iteration_num = 0\n",
        "    epoch_num = 0\n",
        "\n",
        "    epochs = config[\"epochs\"]\n",
        "\n",
        "    while True:\n",
        "        if iteration_num >= patience:\n",
        "            break\n",
        "\n",
        "        # Train and save training results\n",
        "        loss_list_E = []\n",
        "        accuracy_list_E = []\n",
        "        precision_list_E = []\n",
        "        recall_list_E = []\n",
        "        f1_list_E = []\n",
        "\n",
        "        loss_list_S = []\n",
        "        accuracy_list_S = []\n",
        "        precision_list_S = []\n",
        "        recall_list_S = []\n",
        "        f1_list_S = []\n",
        "\n",
        "        loss_list_G = []\n",
        "        accuracy_list_G = []\n",
        "        precision_list_G = []\n",
        "        recall_list_G = []\n",
        "        f1_list_G = []\n",
        "\n",
        "        # Set the model to the \"training\" state (Layers such as Dropout will be triggered only)\n",
        "        model.train()\n",
        "\n",
        "        for train_embeddings, train_labels in tqdm(train_loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            train_embeddings = train_embeddings.to(device)\n",
        "            train_labels = train_labels.to(device)\n",
        "\n",
        "            output = model(train_embeddings)\n",
        "\n",
        "            batch_loss = criterion(output, train_labels.float())\n",
        "\n",
        "            # Back propagation\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            output = output.cpu().detach()\n",
        "            pred = (output > 0).cpu()\n",
        "            y_true = (train_labels > 0).cpu()\n",
        "\n",
        "            # Calculate the performance of each batch and save it\n",
        "            loss = batch_loss.item()\n",
        "\n",
        "            # E\n",
        "            accuracy, precision, recall, f1_score= score(y_true[0], pred[0])\n",
        "            loss_list_E.append(loss)\n",
        "            accuracy_list_E.append(accuracy)\n",
        "            precision_list_E.append(precision)\n",
        "            recall_list_E.append(recall)\n",
        "            f1_list_E.append(f1_score)\n",
        "\n",
        "            # S\n",
        "            accuracy, precision, recall, f1_score= score(y_true[1], pred[1])\n",
        "            loss_list_S.append(loss)\n",
        "            accuracy_list_S.append(accuracy)\n",
        "            precision_list_S.append(precision)\n",
        "            recall_list_S.append(recall)\n",
        "            f1_list_S.append(f1_score)\n",
        "\n",
        "            # G\n",
        "            accuracy, precision, recall, f1_score= score(y_true[2], pred[2])\n",
        "            loss_list_G.append(loss)\n",
        "            accuracy_list_G.append(accuracy)\n",
        "            precision_list_G.append(precision)\n",
        "            recall_list_G.append(recall)\n",
        "            f1_list_G.append(f1_score)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Calculate the performance of each epoch and save it\n",
        "        train_loss_E = np.array(loss_list_E).mean()\n",
        "        train_accuracy_E = np.array(accuracy_list_E).mean()\n",
        "        train_precision_E = np.array(precision_list_E).mean()\n",
        "        train_recall_E = np.array(recall_list_E).mean()\n",
        "        train_f1_E = np.array(f1_list_E).mean()\n",
        "\n",
        "        # S\n",
        "        train_loss_S = np.array(loss_list_S).mean()\n",
        "        train_accuracy_S = np.array(accuracy_list_S).mean()\n",
        "        train_precision_S = np.array(precision_list_S).mean()\n",
        "        train_recall_S = np.array(recall_list_S).mean()\n",
        "        train_f1_S = np.array(f1_list_S).mean()\n",
        "\n",
        "        # G\n",
        "        train_loss_G = np.array(loss_list_G).mean()\n",
        "        train_accuracy_G = np.array(accuracy_list_G).mean()\n",
        "        train_precision_G = np.array(precision_list_G).mean()\n",
        "        train_recall_G = np.array(recall_list_G).mean()\n",
        "        train_f1_G = np.array(f1_list_G).mean()\n",
        "\n",
        "\n",
        "\n",
        "        # Evaluate the current model performance using validate dataset\n",
        "        loss_list_E = []\n",
        "        accuracy_list_E = []\n",
        "        precision_list_E = []\n",
        "        recall_list_E = []\n",
        "        f1_list_E = []\n",
        "\n",
        "        loss_list_S = []\n",
        "        accuracy_list_S = []\n",
        "        precision_list_S = []\n",
        "        recall_list_S = []\n",
        "        f1_list_S = []\n",
        "\n",
        "        loss_list_G = []\n",
        "        accuracy_list_G = []\n",
        "        precision_list_G = []\n",
        "        recall_list_G = []\n",
        "        f1_list_G = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for val_embeddings, val_labels in tqdm(val_loader):\n",
        "\n",
        "                val_embeddings = val_embeddings.to(device)\n",
        "                val_labels = val_labels.to(device)\n",
        "\n",
        "                output = model(val_embeddings)\n",
        "\n",
        "                batch_loss = criterion(output, val_labels.float())\n",
        "\n",
        "                output = output.cpu()\n",
        "                pred = (output > 0).cpu()\n",
        "                sum_pred = torch.sum(pred, dim=1)\n",
        "                non_label_case_idx = (sum_pred < 1).nonzero()\n",
        "\n",
        "                if non_label_case_idx.shape[0] != 0:\n",
        "                    non_label_case = output[non_label_case_idx]\n",
        "                    max_col = torch.argmax(non_label_case, dim=-1)\n",
        "                    raw = non_label_case_idx.reshape(-1,1)\n",
        "                    pred_np = pred.numpy()\n",
        "                    for idx in range(raw.shape[0]):\n",
        "                        pred_np[raw[idx]][max_col[idx]] = True\n",
        "                    pred = torch.from_numpy(pred_np)\n",
        "                pred_list.extend(pred.numpy().astype('float32'))\n",
        "                y_true = (val_labels > 0).cpu()\n",
        "\n",
        "                # Calculate the performance of each batch and save it\n",
        "                loss = batch_loss.item()\n",
        "\n",
        "                # E\n",
        "                accuracy, precision, recall, f1_score= score(y_true[0], pred[0])\n",
        "                loss_list_E.append(loss)\n",
        "                accuracy_list_E.append(accuracy)\n",
        "                precision_list_E.append(precision)\n",
        "                recall_list_E.append(recall)\n",
        "                f1_list_E.append(f1_score)\n",
        "\n",
        "                # S\n",
        "                accuracy, precision, recall, f1_score= score(y_true[1], pred[1])\n",
        "                loss_list_S.append(loss)\n",
        "                accuracy_list_S.append(accuracy)\n",
        "                precision_list_S.append(precision)\n",
        "                recall_list_S.append(recall)\n",
        "                f1_list_S.append(f1_score)\n",
        "\n",
        "                # G\n",
        "                accuracy, precision, recall, f1_score= score(y_true[2], pred[2])\n",
        "                loss_list_G.append(loss)\n",
        "                accuracy_list_G.append(accuracy)\n",
        "                precision_list_G.append(precision)\n",
        "                recall_list_G.append(recall)\n",
        "                f1_list_G.append(f1_score)\n",
        "\n",
        "            # Calculate the performance of each epoch and save it\n",
        "            val_loss_E = np.array(loss_list_E).mean()\n",
        "            val_accuracy_E = np.array(accuracy_list_E).mean()\n",
        "            val_precision_E = np.array(precision_list_E).mean()\n",
        "            val_recall_E = np.array(recall_list_E).mean()\n",
        "            val_f1_E = np.array(f1_list_E).mean()\n",
        "\n",
        "            # S\n",
        "            val_loss_S = np.array(loss_list_S).mean()\n",
        "            val_accuracy_S = np.array(accuracy_list_S).mean()\n",
        "            valn_precision_S = np.array(precision_list_S).mean()\n",
        "            valn_recall_S = np.array(recall_list_S).mean()\n",
        "            val_f1_S = np.array(f1_list_S).mean()\n",
        "\n",
        "            # G\n",
        "            val_loss_G = np.array(loss_list_G).mean()\n",
        "            val_accuracy_G = np.array(accuracy_list_G).mean()\n",
        "            val_precision_G = np.array(precision_list_G).mean()\n",
        "            val_recall_G = np.array(recall_list_G).mean()\n",
        "            val_f1_G = np.array(f1_list_G).mean()\n",
        "\n",
        "\n",
        "        if val_f1_E + val_f1_S + val_f1_G > val_best_f1_E + val_best_f1_S + val_best_f1_G:\n",
        "            ## val result\n",
        "            val_best_f1_E = val_f1_E\n",
        "            val_best_loss_E = val_loss_E\n",
        "            val_best_accuracy_E = val_accuracy_E\n",
        "            val_best_precision_E = val_precision_E\n",
        "            val_best_recall_E = val_recall_E\n",
        "            val_best_f1_S = val_f1_S\n",
        "            val_best_loss_S = val_loss_S\n",
        "            val_best_accuracy_S = val_accuracy_S\n",
        "            val_best_precision_S = val_precision_S\n",
        "            val_best_recall_S = val_recall_S\n",
        "            val_best_f1_G = val_f1_G\n",
        "            val_best_loss_G = val_loss_G\n",
        "            val_best_accuracy_G = val_accuracy_G\n",
        "            val_best_precision_G = val_precision_G\n",
        "            val_best_recall_G = val_recall_G\n",
        "            ## train result\n",
        "            train_best_f1_E = train_f1_E\n",
        "            train_best_loss_E = train_loss_E\n",
        "            train_best_accuracy_E = train_accuracy_E\n",
        "            train_best_precision_E = train_precision_E\n",
        "            train_best_recall_E = train_recall_E\n",
        "            train_best_f1_S = train_f1_S\n",
        "            train_best_loss_S = train_loss_S\n",
        "            train_best_accuracy_S = train_accuracy_S\n",
        "            train_best_precision_S = train_precision_S\n",
        "            train_best_recall_S = train_recall_S\n",
        "            train_best_f1_G = train_f1_G\n",
        "            train_best_loss_G = train_loss_G\n",
        "            train_best_accuracy_G = train_accuracy_G\n",
        "            train_best_precision_G = train_precision_G\n",
        "            train_best_recall_G = train_recall_G\n",
        "            ## other result\n",
        "            best_model = model\n",
        "            iteration_num = 0\n",
        "            best_pred_list = pred_list\n",
        "        else:\n",
        "            iteration_num += 1\n",
        "\n",
        "        epoch_num += 1\n",
        "        # Print out the results of each Epoch\n",
        "        # print?\n",
        "        print(f'Epochs: {epoch_num + 1} || E Train Loss: {train_loss_E: .3f}, Accuracy: {train_accuracy_E: .3f}, Precision: {train_precision_E: .3f}, Recall:{train_recall_E: .3f}, F1: {train_f1_E: .3f} || Val Loss: {val_loss_E: .3f}, Accuracy: {val_accuracy_E: .3f}, Precision: {val_precision_E: .3f}, Recall:{val_recall_E: .3f}, Val F1: {val_f1_E: .3f} || Best F1: {val_best_f1_E: .3f}, Iter: {iteration_num: .0f}')\n",
        "\n",
        "    train_result = [train_best_loss_E, train_best_accuracy_E, train_best_precision_E, train_best_recall_E, train_best_f1_E,\n",
        "                    train_best_loss_S, train_best_accuracy_S, train_best_precision_S, train_best_recall_S, train_best_f1_S,\n",
        "                    train_best_loss_G, train_best_accuracy_G, train_best_precision_G, train_best_recall_G, train_best_f1_G]\n",
        "    val_result = [val_best_loss_E, val_best_accuracy_E, val_best_precision_E, val_best_recall_E, val_best_f1_E,\n",
        "                  val_best_loss_S, val_best_accuracy_S, val_best_precision_S, val_best_recall_S, val_best_f1_S,\n",
        "                  val_best_loss_G, val_best_accuracy_G, val_best_precision_G, val_best_recall_G, val_best_f1_G]\n",
        "\n",
        "    return model, train_result, val_result, best_pred_list"
      ],
      "id": "Z1DJtqZlp4Ku"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qdA2HzHfp4Kv"
      },
      "execution_count": null,
      "outputs": [],
      "id": "qdA2HzHfp4Kv"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "175px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}